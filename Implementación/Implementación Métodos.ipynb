{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436e1fc5",
   "metadata": {},
   "source": [
    "### Definici√≥n de la funci√≥n objetivo y su gradiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534e7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def f(x):\n",
    "    return np.arctan(x[0]**2 + x[1]**2) / np.exp(x[0]) \n",
    "\n",
    "# Gradiente:\n",
    "def grad_f(x):\n",
    "    df_dx = ((2*x[0] / (1 + (x[0]**2 + x[1]**2)**2)) - np.arctan(x[0]**2 + x[1]**2)) / np.exp(x[0])\n",
    "    df_dy = 2 * x[1] / ((1 + (x[0]**2 + x[1]**2)**2) * np.exp(x[0]))\n",
    "    return np.array([df_dx, df_dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91099d",
   "metadata": {},
   "source": [
    "### üîπImplementaci√≥n de M√©todo de M√°ximo Descenso:\n",
    "‚öôÔ∏è Par√°metros de entrada:\n",
    "\n",
    "- x0 ‚Üí punto inicial (vector donde comienza la b√∫squeda).\n",
    "\n",
    "- grad_f ‚Üí gradiente (‚àáf(x)) de la funci√≥n objetivo.\n",
    "\n",
    "- learning_rate ‚Üí tama√±o de paso.\n",
    "\n",
    "- tol ‚Üí tolerancia (si el cambio entre iteraciones es menor que este valor, se detiene el algoritmo).\n",
    "\n",
    "- max_iter ‚Üí n√∫mero m√°ximo de iteraciones permitidas.\n",
    "\n",
    "‚öôÔ∏è Resultados que devuelve:\n",
    "\n",
    "- x_min ‚Üí el √∫ltimo punto calculado (aproximaci√≥n del m√≠nimo de la funci√≥n objetivo).\n",
    "\n",
    "- history ‚Üí lista con todos los puntos visitados.\n",
    "\n",
    "- iteraciones ‚Üí n√∫mero de pasos realizados.\n",
    "\n",
    "- succes ‚Üí True si se detuvo por tolerancia, False si se agotaron las iteraciones.\n",
    "\n",
    "- time ‚Üí cu√°nto tard√≥ en ejecutarse el algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea0736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x0, grad_f, learning_rate=0.1, tol=1e-6, max_iter=100):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    history = [x.copy()]\n",
    "    start = time.time()  \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = grad_f(x)\n",
    "        \n",
    "        x_new = x - learning_rate * grad\n",
    "        history.append(x_new.copy())\n",
    "        \n",
    "        if np.linalg.norm(x_new - x) < tol:\n",
    "            end = time.time()\n",
    "            return x_new, history, i+1, True, end - start\n",
    "        \n",
    "        x = x_new\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    return x, history, max_iter, False, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e05ea",
   "metadata": {},
   "source": [
    "### üîπ Implementaci√≥n del m√©todo Quasi-Newton (BFGS)\n",
    "\n",
    "Elementos utilizados:\n",
    "\n",
    "üî∏ Clase `Callback`\n",
    "\n",
    "Se utiliza para guardar los puntos intermedios (iteraciones) del algoritmo.\n",
    "\n",
    "üî∏funci√≥n `minimize` de la biblioteca `scipy.optimize` \n",
    "\n",
    "Se utiliza para aplicar el **m√©todo BFGS (Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno)**, la t√©cnica de optimizaci√≥n **Quasi-Newton** explicada en el Informe Te√≥rico\n",
    "\n",
    "---\n",
    "\n",
    "‚öôÔ∏è Valores de entrada\n",
    "\n",
    "- f ‚Üí Funci√≥n objetivo a minimizar.  \n",
    "- x0 ‚Üí Vector con el punto inicial de la b√∫squeda.  \n",
    "- method='BFGS' ‚Üí Especifica que se usar√° el m√©todo Quasi-Newton BFGS.  \n",
    "- jac=grad_f ‚Üí Indica la funci√≥n que calcula el gradiente de `f`.  \n",
    "- callback=callback ‚Üí Funci√≥n auxiliar que almacena los puntos visitados durante la optimizaci√≥n.  \n",
    "- options ‚Üí Diccionario con par√°metros de configuraci√≥n del m√©todo:\n",
    "  - `'gtol': 1e-6` ‚Üí Criterio de parada basado en la norma del gradiente.  \n",
    "  - `'disp': False` ‚Üí Desactiva la impresi√≥n de resultados en consola.  \n",
    "  - `'maxiter': 100` ‚Üí N√∫mero m√°ximo de iteraciones permitidas.\n",
    "\n",
    "---\n",
    "‚öôÔ∏è Resultados que devuelve\n",
    "\n",
    "- x_qn ‚Üí Vector con el punto final del proceso (aproximaci√≥n del m√≠nimo).\n",
    "\n",
    "- hist_qn ‚Üí Lista con todos los puntos visitados durante la optimizaci√≥n (trayectoria).\n",
    "\n",
    "- iterations ‚Üí n√∫mero de pasos realizados.\n",
    "\n",
    "- succes ‚Üí True si se detuvo por tolerancia, False si se agotaron las iteraciones.\n",
    "\n",
    "- time_qn ‚Üí Tiempo total de ejecuci√≥n del m√©todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a47867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasi_newton_method(f, grad_f, x0, tol=1e-6, max_iter=100):\n",
    "    class Callback:\n",
    "            def __init__(self):\n",
    "                self.history = []\n",
    "            def __call__(self, xk):\n",
    "                self.history.append(np.array(xk))\n",
    "\n",
    "    callback = Callback()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    res = minimize(f, x0, method='BFGS', jac=grad_f, callback=callback,\n",
    "        options={'gtol': tol, 'disp': False, 'maxiter': max_iter})\n",
    "    \n",
    "    elapsed_time = time.time() - start\n",
    "\n",
    "    # Results\n",
    "    x_min = res.x\n",
    "    history = [np.array(x0)] + callback.history\n",
    "    iterations = res.nit\n",
    "    success = res.success\n",
    "\n",
    "    return x_min, history, iterations, success, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9794ea",
   "metadata": {},
   "source": [
    "### Funcion para graficar los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526f76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecb94a9f",
   "metadata": {},
   "source": [
    "### Funci√≥n `Experiment`\n",
    "\n",
    "La funci√≥n `Experiment` permite automatizar la ejecuci√≥n de experimentos de optimizaci√≥n para distintos par√°metros iniciales y configuraciones. Su funcionamiento resumido es el siguiente:\n",
    "\n",
    "1. **Lectura de configuraciones:** Carga un archivo JSON (`experiment_name`) que contiene los par√°metros de cada experimento, como punto inicial, tolerancia, tasa de aprendizaje y n√∫mero m√°ximo de iteraciones.\n",
    "\n",
    "2. **Ejecuci√≥n de m√©todos de optimizaci√≥n:**  \n",
    "   - Aplica el **M√©todo de M√°ximo Descenso** (`gradient_descent`) con los par√°metros especificados.  \n",
    "   - Aplica el **M√©todo Quasi-Newton** (`quasi_newton_method`) con los mismos par√°metros.\n",
    "\n",
    "3. **Registro de resultados:** Para cada experimento, guarda:\n",
    "   - Las coordenadas finales (`x_min`) y el valor m√≠nimo de la funci√≥n (`f_min`).  \n",
    "   - N√∫mero de iteraciones realizadas y si el m√©todo convergi√≥.  \n",
    "   - Tiempo de ejecuci√≥n de cada m√©todo.\n",
    "\n",
    "4. **Almacenamiento de resultados:** Todos los resultados se guardan en un archivo JSON llamado `results_<experiment_name>` para su posterior an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dec9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Experiment(experiment_name):\n",
    "    # Leer configuraciones desde archivo JSON\n",
    "    with open(experiment_name, \"r\") as f_in:\n",
    "        configs = json.load(f_in)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        # Aplicar M√©todo de M√°ximo Descenso\n",
    "        x_min_gd, history_gd, num_iter_gd, converged_gd, elapsed_gd = gradient_descent(\n",
    "            cfg[\"x0\"], grad_f,\n",
    "            learning_rate=cfg[\"learning_rate\"],\n",
    "            tol=cfg[\"tol\"],\n",
    "            max_iter=cfg[\"max_iter\"]\n",
    "        )\n",
    "\n",
    "        # Aplicar M√©todo de Quasi-Newton\n",
    "        x_min_qn, history_qn, iterations_qn, success_qn, elapsed_qn = quasi_newton_method(\n",
    "            f, grad_f,\n",
    "            x0=cfg[\"x0\"],\n",
    "            tol=cfg[\"tol\"],\n",
    "            max_iter=cfg[\"max_iter\"]\n",
    "        )\n",
    "\n",
    "        #Guardar ambos resultados\n",
    "        resultados.append({\n",
    "            \"params\": cfg,\n",
    "\n",
    "            # Resultados de Gradiente Descendente\n",
    "            \"gradient_descent\": {\n",
    "                \"x_min\": x_min_gd.tolist(),\n",
    "                \"f_min\": float(f(x_min_gd)),\n",
    "                \"num_iter\": num_iter_gd,\n",
    "                \"converged\": converged_gd,\n",
    "                \"time_seconds\": elapsed_gd\n",
    "            },\n",
    "\n",
    "            # Resultados de Quasi-Newton\n",
    "            \"quasi_newton\": {\n",
    "                \"x_min\": x_min_qn.tolist(),\n",
    "                \"f_min\": float(f(x_min_qn)),\n",
    "                \"num_iter\": iterations_qn,\n",
    "                \"converged\": success_qn,\n",
    "                \"time_seconds\": elapsed_qn\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Guardar resultados en archivo JSON\n",
    "    with open(f\"results_{experiment_name}\", \"w\") as f_out:\n",
    "        json.dump(resultados, f_out, indent=4)\n",
    "\n",
    "    print(\"‚úÖ Experimento completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
